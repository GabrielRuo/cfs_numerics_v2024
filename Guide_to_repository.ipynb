{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBs8xwkhcEbo"
      },
      "source": [
        "#A guide to the repository\n",
        "\n",
        "This notebook tries to clarify the purpose of this repository as well as its inner workings. It provides examples to justify the expressions in utils_new.py and illustrate how the functions work. It also explains how to run tests and launch heavier jobs on an HPC server.\n",
        "\n",
        "In order to use the notebook interactively make sure to have installed the packages defined in requirements.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfEsCcy5ecYY"
      },
      "outputs": [],
      "source": [
        "import src.utils_new\n",
        "import os\n",
        "from typing import Tuple, Text, Dict, Union, Any\n",
        "\n",
        "import numpy as np\n",
        "from jax import random,numpy as jnp\n",
        "\n",
        "Params = Tuple[jnp.ndarray, ...]\n",
        "Results = Dict[Text, Union[jnp.ndarray, list, float]]\n",
        "Tup = Tuple[float, float]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKe3_BCDC5nv"
      },
      "source": [
        "The purpose of this code is to to generate space-time points in the context of Causal Fermion systems, compute the Energy (or action) associated with a given distribution of space-time points to then find the optimal configuration which minimises this action.\n",
        "\n",
        "#Physical background: The Causal Action Principle\n",
        "Causal Fermion Systems are a Quantum Gravity theory spearheaded by Felix Finster at Universit√§t Regensburg.\n",
        "\n",
        "For both introductory and in depth material, see [this website](https://causal-fermion-system.com/);\n",
        "\n",
        "\n",
        "In Causal Fermion Systems theory, a spacetime point $x$ lives within an $f$-dimensional Hilbert space $\\mathcal{H}$ and has specific properties defining the subset $\\mathcal{F}$ of space-time points. $x\\in\\mathcal{F}$ means:\n",
        "\n",
        "  * $x$ is a hermitian operator\n",
        "  * $x$ has  at most $n$ positive eigenvalues and $n$ negative eigenvalues yielding  a maximum total of $2n$ non zero eigenvalues. $n$ is called the **spin dimension**\n",
        "  * **trace constraint**: Trace($x$) = some constant here equal to 1\n",
        "\n",
        "The Lagrangian for two spacetime point operators $x$ and $y$ is:\n",
        "\\begin{align}\n",
        "\\mathcal{L}(x,y)=\\frac1{4n}\\sum_{i,j=1}^{2n}\\left(|\\lambda_i|-|\\lambda_j|\\right)^2 = \\sum_{i=1}^{2n}|\\lambda_i|^2-\\frac1{2n} \\left(\\sum_i|\\lambda_i|\\right)^2.\n",
        "\\end{align}\n",
        "where $\\lambda_i$ are the eigenvalues of the product operator $xy$.\n",
        "\n",
        "When considering $m$ space-time points, one combines the Lagragians of all couples of spacetime points using a weighted sum, defining the action of the system:\n",
        "\n",
        "\\begin{equation}\n",
        "    S =\\int{\\rho}{}{}(x)\\int\\rho{}{}y \\mathcal{L}(x,y) = \\sum_{i,j=1}^m c_i c_j\\mathcal{L}(x_i,x_j)=\\vec c^\\intercal (L_{ij}) \\vec c.\n",
        "\\end{equation}\n",
        "\n",
        "with $c$\n",
        " the weight vector which emphasizes some space-time points thus defining a measure on $\\mathcal{F}$. By the **volume constraint**, the total mass on $\\mathcal{F}$ is fixed to 1.\n",
        "\n",
        "The **Causal Action principle** states that the measure on $\\mathcal{F}$ will be such that the action is minimised.\n",
        "\n",
        "The general purpose of this project is to generate large amounts of space-time points and find the optimal configuration (defined by the coordinates of these points and the value of the weights) to visualise solutions of the Causal Action Principle and gain intuition about the measures which satisfy this principle.\n",
        "\n",
        "#Specific purpose of this project\n",
        "\n",
        "More specifically, the purpose of this project is to suggest ways of improving the computation of the action and its minimisation, computing only what is necessary using an efficient parametrisation, taking advantage of the low spin dimension $n$ compared to $f$.\n",
        "\n",
        "#Structure of the project\n",
        "*  Generating a spacetime  point\n",
        "  - Rewriting the Lagrangian to see necessary parameters\n",
        "  - Parametrising a Unitary Matrix\n",
        "  - Generating the parameters\n",
        "  - Building the eigenvectors\n",
        "* Computing the action\n",
        "* Implementing a boundary constraint\n",
        "* Minimising the action\n",
        "  - Two different solvers: `scipy` and `optimistix`\n",
        "  - Reshaping the parameters for the solvers\n",
        "* Running tests\n",
        "  - Set up\n",
        "  - Understanding the run (run.py, run_new.py, run_new_optimistix.py) scripts\n",
        "  - A few test runs\n",
        "* Running the code on an HPC server\n",
        "  - Overview\n",
        "  - Batch job launchers\n",
        "  - Generating and submitting batch scripts\n",
        "\n",
        "\n",
        "\n",
        "#Generating a spacetime point\n",
        "We want to find an efficient way to parametrise a spacetime point $x$ or at least, what is necessary to compute the Lagrangian between two-spacetime points.  Since a spacetime point is a hermitian matrix, it can be written as $ x= UDU^{\\dagger}$. We want to  parametrise $D$ and the unitary matrix $U$ such that we only parametrise what is necessary to compute the action. In order to know what we need, let us rewrite the Lagrangian.\n",
        "\n",
        "## Rewriting the Lagrangian\n",
        "\n",
        "**Notation**: We write , $x = UDU^{\\dagger}$, $y = VEV^{\\dagger}$, with:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "V = \\begin{bmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "v_1\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        "&\n",
        "\\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "v_2\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        " & \\cdots\n",
        " &\n",
        " \\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "v_f\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "U = \\begin{bmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "u_1\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        "&\n",
        "\\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "u_2\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        " & \\cdots\n",
        " &\n",
        " \\begin{pmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "u_f\\\\\n",
        "\\\\\n",
        "\\\\\n",
        "\\end{pmatrix}\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "and\n",
        "\\begin{align}\n",
        "D = \\begin{pmatrix} \\lambda_1 & & & & \\\\ & \\ddots &&& \\\\ &&\\lambda_{2n} && \\\\ &&& 0 & \\\\ &&&& \\ddots\n",
        "    \\end{pmatrix}\n",
        "\\quad\n",
        "E = \\begin{pmatrix} \\nu_1 & & & & \\\\ & \\ddots &&& \\\\ &&\\nu_{2n} && \\\\ &&& 0 & \\\\ &&&& \\ddots\n",
        "    \\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "We want to compute the eigenvalues of $xy$ which we can rewrite as $xy = UDU^{\\dagger}VEV^{\\dagger}$ which has the same eigenvalues as $ M = DU^{\\dagger}VEV^{\\dagger}U$ which explicitly exhibits the dot product between the eigenvectors of $x$ and $y$.\n",
        "\n",
        "Leveraging the zeros in $D$ and $E$, we can write this in a slightly more compact way as $M = GPG^T$\n",
        "with $G = [u_1,\\cdots,u_{2n}][v_1,\\cdots,v_{2n}]^{^\\dagger}$ a Gram-like matrix of the dot products between the first $2n$ eigenvectors of $x$ and $y$, and $P_{ij} = \\lambda_i \\nu_j$ the matrix of products between the non-zero eigenvalues of $x$ and $y$.\n",
        "\n",
        "From this rewriting we see that for each space-time point, all we need is to generate its first $2n$ eigenvectors and its eigenvalues.\n",
        "\n",
        "##Parametrising a unitary matrix.\n",
        "\n",
        "Based on work by [Hubert de Guise et al ](https://arxiv.org/pdf/1708.00735) we show that $U$ can be factorised as:\n",
        "\n",
        "\\begin{align}\n",
        "    U=\\left( R_{f,f-1} R_{f-1,f-2} ... R_{21}\\right)...\\left( R_{f,f-1}...R_{2n-1,2n}\\right).\n",
        "\\end{align}\n",
        "\n",
        "with\n",
        "\n",
        "\\begin{align}\n",
        "R_i(\\alpha_i,\\beta_i) = \\begin{pmatrix} \\exp({i\\alpha_i}) \\cos\\beta_i & - \\sin\\beta_i \\\\ \\sin\\beta_i & \\exp({-i\\alpha_i})\\cos\\beta_i\\end{pmatrix}    \n",
        "\\end{align}\n",
        "\n",
        "$U$ can thus be decomposed as a product of factors which we will call **band-matrices** for reasons not detailed here but more easily seen on a circuit diagram representation of the matrices. We index these band-matrices from $1$ to $2n$ with the first band-matrix corresponding to $\\left( R_{f,f-1} R_{f-1,f-2} ... R_{21}\\right)$\n",
        "\n",
        "The first band-matrix can be written as:\n",
        "\n",
        "\\begin{align}\n",
        "   & \\left( R_{f,f-1} R_{f-1,f-2} ... R_{21}\\right)=\n",
        "\\\\&\n",
        "\\begin{pmatrix}\n",
        "    \\exp{i\\alpha_1}\\cos\\frac{\\beta_1}2 & -\\sin\\frac{\\beta_1}2 & 0 & \\dots \\\\\n",
        "    & \\ddots & \\\\\n",
        "    \\exp{i\\alpha_k}\\cos\\frac{\\beta_k}2 \\prod_{i=1}^{k-1} \\sin\\frac{\\beta_i}2 & & \\exp{i(\\alpha_k-\\alpha_{k-1})}\\cos\\frac{\\beta_k}2 \\cos\\frac{\\beta_{k-1}}2 & -\\sin\\beta_k/2 & 0 & \\dots\\\\\n",
        "    \\vdots & & \\exp{i(\\alpha_k-\\alpha_{l-1})}\\cos\\frac{\\beta_k}2\\cos\\frac{\\beta_{l-1}}2\\prod_{i=l}^{k-1}\\sin\\frac{\\beta_i}2 & \\ddots & \\dots \\\\\n",
        "    \\vdots &\\dots & \\\\\n",
        "    \\prod_{i=1}^{f-1} \\sin\\frac{\\beta_i}2 & \\dots & \\exp{-i\\alpha_{l-1}}\\cos\\frac{\\beta_{l-1}}2\\prod_{i=l}^{f-1}\\sin\\frac{\\beta_i}2 & \\dots & \\exp{-i\\alpha_{f-1}}\\cos\\frac{\\beta_{f-1}}2\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Similarly, the other band_matrices have the same shape but are progressively shifted to the right and the bottom such that the $i$th band-matrix's first $i$ rows have 1s on the diagonal and 0s everwhere else.\n",
        "\n",
        "This is seen in the example below:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AsIDuQwzV60z"
      },
      "outputs": [],
      "source": [
        "m = 1; n = 1; f = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqbyjOLWcxjg",
        "outputId": "b3eae076-9fdf-4926-9ecb-840d653f66fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Band-matrix:\n",
            "[[ 0.6+0.1j -0.8+0.j   0. +0.j   0. +0.j ]\n",
            " [-0.3+0.2j -0.2+0.2j -0.9+0.j   0. +0.j ]\n",
            " [-0.4+0.6j -0.2+0.5j  0.5-0.1j  0. +0.j ]\n",
            " [ 0. +0.j   0. -0.j  -0. +0.j  -0.6-0.8j]]\n",
            "\n",
            "Second Band-matrix:\n",
            "[[ 1. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
            " [ 0. +0.j  -0. -0.4j -0.9+0.j   0. +0.j ]\n",
            " [ 0. +0.j   0.4+0.8j -0.4+0.1j  0.1+0.j ]\n",
            " [ 0. +0.j  -0.1+0.j   0. -0.1j  0.4-0.9j]]\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "seed = 19\n",
        "key = random.PRNGKey(seed)\n",
        "subkeys = random.split(key,4)\n",
        "\n",
        "band_number_1 = 1\n",
        "band_number_2 =2\n",
        "\n",
        "alphas_band_1 = jnp.squeeze(random.uniform(subkeys[0],(m,f-band_number_1), minval = 0, maxval = 4*jnp.pi))\n",
        "betas_band_1 = jnp.squeeze(random.uniform(subkeys[1],(m,f-band_number_1), minval = 0, maxval = jnp.pi/2))\n",
        "\n",
        "alphas_band_2 = jnp.squeeze(random.uniform(subkeys[2],(m,f-band_number_2), minval = 0, maxval = jnp.pi/2))\n",
        "betas_band_2 = jnp.squeeze(random.uniform(subkeys[3],(m,f-band_number_2), minval = 0, maxval = 4*jnp.pi))\n",
        "\n",
        "band_unitary_1 = make_single_band_unitary(alphas_band_1,betas_band_1, f,f)\n",
        "band_unitary_2 = make_single_band_unitary(alphas_band_2, betas_band_2, f,f)\n",
        "print(\"First Band-matrix:\")\n",
        "print(jnp.round(band_unitary_1*1e1)/1e1, end = \"\\n\\n\")\n",
        "print(\"Second Band-matrix:\")\n",
        "print(jnp.round(band_unitary_2*1e1)/1e1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pZaW0hdcx55"
      },
      "source": [
        "The takeway message from this is that we will be able to parametrise our unitary matrix using band-matrices for which we have an analytic expression in terms of simple trigonometric functions based on angles $\\alpha$ and $\\beta$.\n",
        "\n",
        "A keen eye will notice these terms appear in three combinations of the form:\n",
        "\n",
        "\n",
        "1.   $\\cos{\\frac{\\beta}{2}}\\exp{i\\alpha}$\n",
        "2.   $\\cos{\\frac{\\beta}{2}}\\exp{-i\\alpha}$\n",
        "3.   $\\sin{\\frac{\\beta}{2}}$\n",
        "\n",
        "which we will call **building blocks**.\n",
        "\n",
        "\n",
        "\n",
        "## Generating the parameters\n",
        "\n",
        "The parameters we will be needing are thus the positive and negative eigenvalues defining the spectrum of a space-time point, the $\\alpha$s and $\\beta$s which define its eigenvectors and the weight associated to each space-time point.\n",
        "\n",
        "These are generated by the `init_params` function. The only caveat is that  the `pos_spectrum` and `neg_spectrum` outputs are not quite yet eigenalues. These must satisfy a trace constraint which we enforce through the `make_spectra` function.\n",
        "\n",
        "We then convert the $\\alpha$s and $\\beta$s to the three building blocks which we defined earlier using the `get_building_blocks` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "3RA676UHpfzr"
      },
      "outputs": [],
      "source": [
        "weights, pos_spectrum, neg_spectrum, alphas, betas = init_params(key,n,f,m)\n",
        "spectra = make_spectra(pos_spectrum, neg_spectrum)\n",
        "cos_betas_exp_pos_alphas, cos_betas_exp_neg_alphas, sin_betas = get_building_blocks(alphas,betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTWr8NeuQdD3",
        "outputId": "0af31d01-1d02-4cd6-a41b-8d22c0e4c7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note that the first index gives index of space-time point among the m = 1 space-time points\n",
            "\n",
            "alphas:\n",
            "[[4.88847    1.0773908  0.64114255 7.812752   4.402076  ]]\n",
            "\n",
            "spectra: The n = 1 positive eigenvalues followed by the n = 1, negative eigenvalues: \n",
            "[[ 2. -1.]]\n",
            "\n",
            "cos_betas_exp_pos_alphas: all the values of the block of cos_betas_exp_pos_alphas\n",
            "[[ 0.06862392-0.3856927j   0.2967985 +0.55190545j  0.06864359+0.05123017j\n",
            "   0.01394637+0.33806726j -0.10614584-0.3310097j ]]\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "print(\"Note that the first index gives index of space-time point among the m = {} space-time points\".format(m), end = \"\\n\\n\")\n",
        "print(\"alphas:\")\n",
        "print(alphas, end = \"\\n\\n\")\n",
        "print(\"spectra: The n = {} positive eigenvalues followed by the n = {}, negative eigenvalues: \".format(n,n))\n",
        "print(spectra, end = '\\n\\n')\n",
        "print(\"cos_betas_exp_pos_alphas: all the values of the block of cos_betas_exp_pos_alphas\")\n",
        "print(cos_betas_exp_pos_alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwLO8bBKsuQT"
      },
      "source": [
        "## Building the eigenvectors:\n",
        "We have **building blocks** but we need to arange them in certain positions to actually build **band-matrices** and eventually a unitary matrix.\n",
        "\n",
        "Within a building block, say the building block of all the $\\sin{\\frac{\\beta_i}{2}}$s, each $\\sin{\\frac{\\beta_i}{2}}$ is itself a sub-building block of a band-matrix.\n",
        "\n",
        "For example, in $\\left( R_{f,f-1} R_{f-1,f-2} ... R_{21}\\right)$, we identify that $\\sin{\\frac{\\beta_2}{2}}$ appears at the following positions in red:\n",
        "\n",
        "\\begin{align}\n",
        "   & \\left( R_{f,f-1} R_{f-1,f-2} ... R_{21}\\right)=\n",
        "\\\\&\n",
        "\\begin{pmatrix}\n",
        "    \\exp{i\\alpha_1}\\cos\\frac{\\beta_1}2 & -\\color{red}{\\sin\\frac{\\beta_1}2} & 0 & \\dots \\\\\n",
        "    & \\ddots & \\\\\n",
        "    \\exp{i\\alpha_k}\\cos\\frac{\\beta_k}2 \\prod_{i=1}^{k-1} \\color{red}{\\sin\\frac{\\beta_i}2} & & \\exp{i(\\alpha_k-\\alpha_{k-1})}\\cos\\frac{\\beta_k}2 \\cos\\frac{\\beta_{k-1}}2 & -\\sin\\beta_k/2 & 0 & \\dots\\\\\n",
        "    \\vdots & & \\exp{i(\\alpha_k-\\alpha_{l-1})}\\cos\\frac{\\beta_k}2\\cos\\frac{\\beta_{l-1}}2\\prod_{i=l}^{k-1}\\sin\\frac{\\beta_i}2 & \\ddots & \\dots \\\\\n",
        "    \\vdots &\\dots & \\\\\n",
        "    \\prod_{i=1}^{f-1} \\color{red}{\\sin\\frac{\\beta_i}2} & \\dots & \\exp{-i\\alpha_{l-1}}\\cos\\frac{\\beta_{l-1}}2\\prod_{i=l}^{f-1}\\sin\\frac{\\beta_i}2 & \\dots & \\exp{-i\\alpha_{f-1}}\\cos\\frac{\\beta_{f-1}}2\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "We can therefore build a **mask matrix** associated with $\\sin{\\frac{\\beta_1}{2}}$ with 1s where there should be a $\\sin{\\frac{\\beta_1}{2}}$ term and 0s elsewhere.\n",
        "\n",
        "We build similar masks for all $\\sin{\\frac{\\beta_i}{2}}$ and for the other two building blocks.\n",
        "\n",
        "It turns out the shape of the mask matrices follows relatively simple patterns as a function of $i$ and the index of the band-matrix.\n",
        "\n",
        "This is performed by the function `make_masks`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA3kbPl9yj7Y",
        "outputId": "39bcd849-00a2-4ca2-e9a3-dd44d97f60d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The masks for band-matrix number 1 for the sin building block: \n",
            "\n",
            "Mask for sin(beta_1):\n",
            "[[0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n",
            "\n",
            "Mask for sin(beta_2):\n",
            "[[0 0 0 0]\n",
            " [0 0 1 0]\n",
            " [1 1 0 0]\n",
            " [1 1 0 0]]\n",
            "\n",
            "Mask for sin(beta_3):\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 1]\n",
            " [1 1 1 0]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "mask_cos_exp_pos_1, mask_cos_exp_neg_1,mask_sin_1 = make_masks(f,f,band_number = band_number_1)\n",
        "print(\"The masks for band-matrix number {} for the sin building block: \".format(band_number_1))\n",
        "print(\"\")\n",
        "for i in range(f-band_number_1):\n",
        "  print(\"Mask for sin(beta_{}):\".format(i+1))\n",
        "  print(mask_sin_1[i]*1)\n",
        "  print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utyz_6JeeaHp"
      },
      "source": [
        "We now need to multiply each mask by its associated value and add together the masks of a given band-matrix to get a full band matrix.\n",
        "\n",
        "This is done by the function `make_single_band_unitary`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTLuuMqrhkEa",
        "outputId": "74682a2d-6a59-4538-9436-50b5adb59b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The masks for the sin building block:\n",
            "\n",
            "[[[0 1 0 0]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 1 0]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 0]]\n",
            "\n",
            " [[0 0 0 0]\n",
            "  [0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 1 1 0]]]\n",
            "\n",
            "The sin(beta_i/2) values for the sin building block:\n",
            "\n",
            "[0.9098873  0.94499505 0.28154582]\n",
            "\n",
            "Each sin(beta_i/2) value mutiplied by associated mask:\n",
            "\n",
            "[[0.   0.91 0.   0.  ]\n",
            " [0.91 0.   0.   0.  ]\n",
            " [0.91 0.   0.   0.  ]\n",
            " [0.91 0.   0.   0.  ]]\n",
            "\n",
            "[[0.   0.   0.   0.  ]\n",
            " [0.   0.   0.94 0.  ]\n",
            " [0.94 0.94 0.   0.  ]\n",
            " [0.94 0.94 0.   0.  ]]\n",
            "\n",
            "[[0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.28]\n",
            " [0.28 0.28 0.28 0.  ]]\n",
            "\n",
            "Add 1s where necessary before multiplying all these matrices:\n",
            "\n",
            "[[[1.   0.91 0.   0.  ]\n",
            "  [0.91 1.   1.   0.  ]\n",
            "  [0.91 1.   1.   1.  ]\n",
            "  [0.91 1.   1.   1.  ]]\n",
            "\n",
            " [[1.   1.   0.   0.  ]\n",
            "  [1.   1.   0.94 0.  ]\n",
            "  [0.94 0.94 1.   1.  ]\n",
            "  [0.94 0.94 1.   1.  ]]\n",
            "\n",
            " [[1.   1.   0.   0.  ]\n",
            "  [1.   1.   1.   0.  ]\n",
            "  [1.   1.   1.   0.28]\n",
            "  [0.28 0.28 0.28 1.  ]]]\n",
            "\n",
            "The combination of all these terms in one matrix:\n",
            "\n",
            "[[1.   0.91 0.   0.  ]\n",
            " [0.91 1.   0.94 0.  ]\n",
            " [0.86 0.94 1.   0.28]\n",
            " [0.24 0.27 0.28 1.  ]]\n",
            "\n",
            "Now do the same for the other two building blocks, combine everything, add - signs where necessary and get band-matrix number 1:\n",
            "\n",
            "[[ 0.39+0.15j -0.91+0.j    0.  +0.j    0.  +0.j  ]\n",
            " [-0.21-0.21j -0.12-0.05j -0.94+0.j    0.  +0.j  ]\n",
            " [ 0.27-0.78j -0.02-0.38j  0.14+0.28j -0.28+0.j  ]\n",
            " [ 0.24+0.j    0.1 -0.04j -0.06+0.07j  0.31+0.91j]]\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "band_matrix = make_single_band_unitary(alphas_band_1,betas_band_1,f,f)\n",
        "\n",
        "#We now decompose the first steps of make_single_band_unitary for clarity\n",
        "\n",
        "#extract the building blocks and masks\n",
        "building_blocks = get_building_blocks(alphas_band_1, betas_band_1)\n",
        "masks = make_masks(f,f,band_number_1)\n",
        "\n",
        "#extract masks and sin(beta_i/2) values for the sin building block\n",
        "mask = masks[2]\n",
        "building_block = building_blocks[2]\n",
        "\n",
        "#Multiply the masks and sin values together\n",
        "band_matrix_sub_building_blocks = mask*building_block[:,jnp.newaxis,jnp.newaxis]\n",
        "\n",
        "#Combine the different matrices for each sin(beta_i/2)\n",
        "  # Add 1s where the terms will be non-zero\n",
        "ones_tril= jnp.tril(jnp.ones((f,f))) + jnp.eye(f,k = 1)\n",
        "band_matrix_sub_building_blocks_with_ones = band_matrix_sub_building_blocks + ones_tril - mask\n",
        "\n",
        "  #multiply the matrices together\n",
        "band_matrix_building_block = jnp.prod(band_matrix_sub_building_blocks_with_ones, axis =0)\n",
        "\n",
        "print(\"The masks for the sin building block:\", end = \"\\n\\n\")\n",
        "print(mask*1, end = \"\\n\\n\")\n",
        "print(\"The sin(beta_i/2) values for the sin building block:\", end = \"\\n\\n\")\n",
        "print(building_block, end = \"\\n\\n\")\n",
        "print(\"Each sin(beta_i/2) value mutiplied by associated mask:\", end = \"\\n\\n\")\n",
        "for i in range(f-band_number_1):\n",
        "  print(jnp.round(band_matrix_sub_building_blocks[i]*1e2)/1e2, end = \"\\n\\n\")\n",
        "print(\"Add 1s where necessary before multiplying all these matrices:\", end = \"\\n\\n\")\n",
        "print(jnp.round(band_matrix_sub_building_blocks_with_ones*1e2)/1e2, end = \"\\n\\n\")\n",
        "print(\"The combination of all these terms in one matrix:\", end = \"\\n\\n\")\n",
        "print(jnp.round(band_matrix_building_block*1e2)/1e2, end = \"\\n\\n\")\n",
        "print(\"Now do the same for the other two building blocks, combine everything, add - signs where necessary and get band-matrix number {}:\".format(band_number_1), end = \"\\n\\n\")\n",
        "print(jnp.round(band_matrix*1e2)/1e2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #PAS SUR QUE num_masks soit un nom id√©al\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IdxoxpnKtk7"
      },
      "source": [
        "We can now multiply all the band-matrices together and get the eigenvectors of a space-time point $x$ as the columns of $U$.\n",
        "\n",
        "Since we only care about the first $2n$ eigenvectors of $x$, we can simplify the caclulation and only consider the first $2n$ columns of the last band-matrix and multiply it through the other band-matrices.\n",
        "\n",
        "This is performed by the function `make_single_eigenvectors(alphas: jnp.ndarray ,betas:jnp.ndarray,f:int, n:int)` which is then vectorised to handle $m$ space-time points as `make_eigenvectors`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar-6wUfUMJ4Y",
        "outputId": "c9917827-f3d3-4e2d-c0d8-1c37b3d5f8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " eigenvectors: The columns of the matrix are the 2n = 2 eigenvectors:\n",
            "\n",
            "[[ 0.07-0.39j -0.01-0.31j]\n",
            " [ 0.27+0.51j  0.02+0.18j]\n",
            " [ 0.05+0.04j -0.9 -0.02j]\n",
            " [ 0.71+0.j   -0.24-0.06j]]\n"
          ]
        }
      ],
      "source": [
        "eigenvectors = make_single_eigenvectors(alphas[0], betas[0],f, n)\n",
        "print(\" eigenvectors: The columns of the matrix are the 2n = {} eigenvectors:\".format(2*n), end = \"\\n\\n\")\n",
        "print(jnp.round(eigenvectors*1e2)/1e2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_G0d0W1NWYi"
      },
      "source": [
        "#Computing the Action\n",
        "\n",
        "Now we can start computing the Lagrangian between two space-time points.\n",
        "We thus use the formulae given above to compute the Lagrangian between two space-time points $x$ and $y$ in `make_lagrangian_n`.\n",
        "\n",
        "Since we had a special focus on the case $n=1$ we computed a further simplified expression for the Lagrangian in that case, expressed in the function `make_lagrangian_1`.\n",
        "\n",
        "We then sum the Lagrangians over all pairs of the $m$ spacetime points, taking the weights into account with the `action` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIg8i2ZTPL__",
        "outputId": "0b06638f-512e-48ba-e5ec-0017c0bc02b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Lagrangian between the first (i=0) and second (j=1) space-time points is:  0.54841936\n",
            "The total action across the m points is: 1.6683025\n"
          ]
        }
      ],
      "source": [
        "# Generate m=3 space-time points, their spectrum and eigenvectors\n",
        "params = init_params(key,n,f,m=3, sigma_weights = 0.01,init_spectrum = 1, sigma_spectrum = 0.01)\n",
        "spectra = make_spectra(pos_spectrum = params[1],neg_spectrum = params[2])\n",
        "eigenvectors = make_eigenvectors(params[3], params[4],f, n)\n",
        "\n",
        "lag = make_lagrangian_n(spectra,eigenvectors,i=0,j=1)\n",
        "action_tot = action(params)\n",
        "\n",
        "print(\"The Lagrangian between the first (i=0) and second (j=1) space-time points is \", lag)\n",
        "print(\"The total action across the m points is\" , action_tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF7WxQ4BKv-N"
      },
      "source": [
        "#The boundedness constraint\n",
        "\n",
        "We can add another constraint to the optimisation problem. Until now, volume and trace constraints had been implemented directly in the definition of the parameters, letting us deal with an unconstrained optimisation problem. It will now be difficult to do the same with the boundedness constraint which simply imposes some  upper bound on the weighted sum of the eigenvalues of all pairs of space-time points as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathcal{T}(\\rho) := \\iint_{\\mathcal{F} \\times \\mathcal{F}}\n",
        "\\left( \\sum_{i=1}^{2n} |\\lambda_i^{xy}| \\right)^2\n",
        "d\\rho(x) \\, d\\rho(y) \\leq C\n",
        "\\end{equation}\n",
        "\n",
        "It is computed using the function `boundedness(params: Params)`\n",
        "\n",
        "It is difficult to implement this as an a priori constraint on the parameters as one needs to take into account the eigenvalues of all couples of space-time points.\n",
        "\n",
        "We thus implement this highly non-linear constraint using a barrier term\n",
        "\\begin{equation}\n",
        "\\mathcal{L}_{bounded}= \\mathcal{L}-\\frac{1}{k}\\log(C - \\tau)\n",
        "\\end{equation}\n",
        "\n",
        "where we chose $k = -10^3\\log({0.1})mn^3$\n",
        "\n",
        "This loss is computed by the function `action_with_barrier_bnd_constraint`\n",
        "\n",
        "Note however that for this barrier to be well defined, $\\tau$ must be smaller than $C$ from the start. It is hence necessary to initialise the parameters in such a way that they satisfy the boundedness constraint.\n",
        "\n",
        "This is called **feasibility initialisation**.\n",
        "\n",
        "\n",
        "For this purpose, before minimising the causal action we drive the parameters in the right region by first solving a different optimisation problem whose minimum satisfies the boundedness constraint.\n",
        "\n",
        "We thus minimise the loss:\n",
        "\\begin{equation}\n",
        "\\mathcal{L}_{feasibility} = \\max(\\tau-C,0)\n",
        "\\end{equation}.\n",
        "\n",
        "This is implemented by the functions `feasibility_cost` which defines this loss and `satisfy_feasibility` which solves the feasibility optimisation problem within the class `Optimistix_BFGS_Solver`.\n",
        "\n",
        "#Optimising the action\n",
        "\n",
        "## Two different solvers\n",
        "\n",
        "We build two alternative solvers, one  using `jax.scipy.minimise.lbfgs` and the other using the library `optimistix`.\n",
        "\n",
        "As can be read at the [following adress](https://docs.kidger.site/optimistix/faq/), `jax.scipy.minimize` is deprecated and is not at the state of the art.\n",
        "\n",
        "Although we have seen that on comparable tests (small $f$, large $m$) `optimistix` clearly outperforms `jax.scipy.minimise.lbfgs`, at the time of this project the LBFGS algorithm was not implemented on `optimistix`. For large values of $f$, the intrinsic speedup of LBFGS compared to BFGS thus makes `jax.scipy.minimise.lbfgs` still valuable.\n",
        "\n",
        "There are thus two optimiser functions in this code: `optimize_scipy ` and `optimize_optimistix`.\n",
        "\n",
        "1. `optimize.scipy`:\n",
        "  -  Unlike optimistix which automatically computes the gradient, `scipty.minimise` takes as input both the cost function and its gradient.\n",
        "  - Our optimiser works in two steps. First it implements lbfgs for a certain number of steps for speed, and then it applies bfgs to find a precise solution.\n",
        "  - A detailed `Callback` class enables us to collect datapoints about the evolution of the optimisation by  storing the parameter values and the action every `checkpoint_freq`optimisation steps.\n",
        "\n",
        "2. `optimize_optimistix` is built on top of a class `Optimistix_BFGS_Solver`\n",
        "  - This class enables us to define a tailor-made solver which can minimise the causal action with or without a boundedness constraint.\n",
        "  - It defines the method `_optimise` which simply implements `optimistix.BFGS` on a given cost_function.\n",
        "  - The methods `minimise_unconstrained_action` and `minimise_constrained_action` then  apply `_optimise` with the appropriate loss function (and with the initial `satisfy_feasibility` step in the constrained case).\n",
        "  - Defining Callback functions on optimistix is less straightforward thus  there is no Callback function here\n",
        "\n",
        "## Reshaping the inputs and outputs for the optimisers\n",
        "\n",
        "Optimisers need the parameters to be flattened. We thus build the functions `_flatten_params`, `_reconstruct_params`, `action_flat_params`.\n",
        "\n",
        "The flattened parameters and `action_flat_params` will be given as an argument to the solvers which will then try to find the optimal parameters.\n",
        "\n",
        "Optimistix requires the cost function to be written slightly differently as it must have as input both the parameters which are optimised and the constant arguments `args` hence the functions `_feasibility_cost_with_args` or `_action_with_args`\n",
        "\n",
        "Regarding outputs, when runnning the optimisation, scipy.minimise and optimistix have outputs of a different format. There are hence parts of the code of `optimize_optimistix` and `optimize_scipy` which reshape this output so that both optimisers have a similar output.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "xSepbN1Sq84O"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "m = 2; n = 1; f = 4\n",
        "seed = 19\n",
        "key = random.PRNGKey(seed)\n",
        "\n",
        "lbfgs_maxiter = 10000\n",
        "lbfgs_gtol = 1e-7\n",
        "lbfgs_ftol = 1e-9\n",
        "lbfgs_maxcor = 70\n",
        "lbfgs_maxls = 20\n",
        "\n",
        "bfgs_maxiter = 10000\n",
        "bfgs_rtol= 1e-7\n",
        "bfgs_atol= 1e-9\n",
        "bfgs_gtol = 1e-7\n",
        "\n",
        "sigma_weights = 0.01\n",
        "init_spectrum = 1\n",
        "sigma_spectrum = 0.01\n",
        "\n",
        "lbfgs_options = {\n",
        "    \"maxiter\": lbfgs_maxiter,\n",
        "    \"maxfun\": 2 * lbfgs_maxiter,\n",
        "    \"disp\": 50,\n",
        "    \"gtol\": lbfgs_gtol,\n",
        "    \"ftol\": lbfgs_ftol,\n",
        "    \"maxcor\": lbfgs_maxcor,\n",
        "    \"maxls\": lbfgs_maxls,\n",
        "  }\n",
        "bfgs_options = {\n",
        "\"maxiter\": bfgs_maxiter,\n",
        "\"disp\": True,\n",
        "\"gtol\": bfgs_gtol,\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n2Rm9OSp5c1",
        "outputId": "664149df-5224-45c8-bc15-4bd0cc7bec7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py:708: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Current function value: 0.250000\n",
            "         Iterations: 0\n",
            "         Function evaluations: 71\n",
            "         Gradient evaluations: 60\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "key, subkey = random.split(key)\n",
        "params_0 = init_params(subkey, n, f, m,sigma_weights,init_spectrum,sigma_spectrum)\n",
        "#optimistix:\n",
        "final_params_optimistix, bfgs_res_optimistix = optimize_optimistix( params_0, n, f, m, bfgs_maxiter, bfgs_rtol, bfgs_atol)\n",
        "\n",
        "#scipy\n",
        "\n",
        "  #We bypass the callback function in this simple example by setting a very large checkpoint frequency.\n",
        "  #We will thus not need an output directory for the Callback function:\n",
        "\n",
        "checkpoint_freq = lbfgs_maxiter + bfgs_maxiter\n",
        "out_dir  = None\n",
        "\n",
        "final_params_scipy, bfgs_res_scipy = optimize_scipy(\n",
        "    params_0, n, f, m, lbfgs_options, bfgs_options, out_dir,\n",
        "    checkpoint_freq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNuHOpnq2N_0",
        "outputId": "a8f77cc3-e3c1-4a29-cd97-be86b299249a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimistix:\n",
            "\n",
            "final_params_optimistix: (Array([0.00560452, 0.00542667], dtype=float32), Array([[8.335797],\n",
            "       [7.067811]], dtype=float32), Array([[-7.6338406],\n",
            "       [-6.397291 ]], dtype=float32), Array([[ 6.070735 ,  7.2938066,  3.4974928, 10.937419 ,  5.341822 ],\n",
            "       [ 1.5411974, 12.518247 ,  1.6796926,  1.5048906,  8.7280655]],      dtype=float32), Array([[0.7808373 , 0.94757605, 0.35858634, 0.03970427, 1.3226327 ],\n",
            "       [1.1094694 , 1.5514561 , 0.7609991 , 0.9170569 , 0.489293  ]],      dtype=float32))\n",
            "bfgs_res_optimistix:  {'action': array([0.25000098], dtype=float32), 'boundedness': array([0.50000197], dtype=float32), 'n_iterations': array([53], dtype=int32), 'n': array(1), 'f': array(4), 'm': array(2)}\n",
            "\n",
            "scipy:\n",
            "\n",
            "final_params_scipy: (Array([0.00471749, 0.0043963 ], dtype=float32), Array([[8.048061],\n",
            "       [8.532693]], dtype=float32), Array([[-7.3448763],\n",
            "       [-7.862127 ]], dtype=float32), Array([[ 6.090608 ,  7.299733 ,  3.4826152, 10.937173 ,  5.3417554],\n",
            "       [ 1.5212052, 12.515652 ,  1.6924844,  1.5055017,  8.725015 ]],      dtype=float32), Array([[0.76104254, 0.939783  , 0.3782431 , 0.05306504, 1.3230222 ],\n",
            "       [1.1169235 , 1.5525584 , 0.79167104, 0.9266287 , 0.48599562]],      dtype=float32))\n",
            "bfgs_res_scipy:  {'action': array([0.25000018], dtype=float32), 'boundedness': array([0.50000036], dtype=float32), 'n_iterations': array([], dtype=float64), 'n': array(1), 'f': array(4), 'm': array(2), 'lbfgs_iterations': array(25), 'lbfgs_func_eval': array(60), 'lbfgs_jac_eval': array(60), 'lbfgs_status': array(0), 'lbfgs_success': array(True), 'bfgs_iterations': array(0), 'bfgs_func_eval': array(71), 'bfgs_jac_eval': array(60), 'bfgs_status': array(2), 'bfgs_success': array(False)}\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "print(\"optimistix:\", end  = \"\\n\\n\")\n",
        "print(\"final_params_optimistix:\", final_params_optimistix)\n",
        "print(\"bfgs_res_optimistix: \", bfgs_res_optimistix, end = \"\\n\\n\")\n",
        "\n",
        "print(\"scipy:\", end  = \"\\n\\n\")\n",
        "print(\"final_params_scipy:\", final_params_scipy)\n",
        "print(\"bfgs_res_scipy: \", bfgs_res_scipy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZIhC2A8rakh",
        "outputId": "e5bc4389-9e8b-40e2-c6c2-b3074476f5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scipy:\n",
            "\n",
            "final action: [0.25000018]\n",
            "number of lbfgs iterations: 25\n",
            "number of bfgs iterations: 0\n",
            "Final weights:  [0.00471749 0.0043963 ]\n",
            "\n",
            "optimistix:\n",
            "\n",
            "final action: [0.25000098]\n",
            "number of iterations: [53]\n",
            "Final weights:  [0.00560452 0.00542667]\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "#scipy\n",
        "print(\"scipy:\", end = \"\\n\\n\")\n",
        "print(\"final action:\", bfgs_res_scipy[\"action\"])\n",
        "print(\"number of lbfgs iterations:\", bfgs_res_scipy['lbfgs_iterations'])\n",
        "print(\"number of bfgs iterations:\",bfgs_res_scipy['bfgs_iterations'])\n",
        "print(\"Final weights: \", final_params_scipy[0], end = \"\\n\\n\")\n",
        "#optimistix\n",
        "print(\"optimistix:\", end = \"\\n\\n\")\n",
        "print(\"final action:\", bfgs_res_optimistix[\"action\"])\n",
        "print(\"number of iterations:\", bfgs_res_optimistix['n_iterations'])\n",
        "print(\"Final weights: \", final_params_optimistix[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7O0MuJ79bSa"
      },
      "source": [
        "#Running test optimisation:\n",
        "\n",
        "\n",
        "##Set up\n",
        "\n",
        "Set up a virtual environment  using\n",
        "\n",
        " `conda create -n cfs_v2024_env python=3.10`\n",
        "\n",
        "Then activate that environment using\n",
        "\n",
        " `conda activate cfs_v2024_env `\n",
        "\n",
        "Navigate to the cfs_numerics_v2024 folder then install the requirements using\n",
        "\n",
        "`pip install -r requirements.txt`\n",
        "\n",
        "##Understanding the run python scripts\n",
        "\n",
        "There are three different run python scripts:\n",
        "- run.py: uses the parametrisation built by Niki Kilbertus in [the original paper](https://arxiv.org/pdf/2201.06382v1)\n",
        "- run_new.py: implements the new parametrisation using the scipy.minimise optimiser\n",
        "- run_new_optimistix.py: implements the new parametrisation using optimistix\n",
        "\n",
        "###Inputs\n",
        "\n",
        "Since we want to run the optimisation automatically using scripts, we use absl flags to define variables which we can modify in scripts.\n",
        "\n",
        "For example,  in run.py one can see:\n",
        "`flags.DEFINE_integer(\"n\", 2, \"The spin dimension.\")`\n",
        "defines an integer  variable $n$ with an initial value of 2, labeled as \"the spin dimension\"\n",
        "\n",
        "We can modify this variable when we call run.py in the command line with a script such as:\n",
        "\n",
        "`python ./src/run.py --f=2 --n=1 --m=16 --seed=4`\n",
        "\n",
        "where `--n = 1` inputs a different value to the flag.\n",
        "\n",
        "###Outputs\n",
        "\n",
        "All three run files will store their output in the directory `outdir = ..\\result` stored 1 directory up relative to where the run files are run. If that directory does not exist yet it is made using\n",
        "\n",
        "`if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)`\n",
        "\n",
        "There are three kinds of outputs:\n",
        "* loggings\n",
        "  - the absl library enables one to keep track of what is being done during the calculations by writing logings while the program is run both in the console and in a separate file.\n",
        "    - `FLAGS.alsologtostderr = True` ensures the loggings are written in the console\n",
        "    - `FLAGS.log_dir = out_dir` defines wehre the logs are stored (FLAGS.log_dir is an absl keyword)\n",
        "    - `logging.get_absl_handler().use_absl_log_file(program_name=\"run\")`stores the loggings as `run.INFO`\n",
        "      - All the content in `logging.info(\"content\")` will be stored in a file somewhat like `run.INFO`\n",
        "* checkpoints:\n",
        "  - the scipy optimiser calls a checkpoint function:\n",
        "    `final_params, bfgs_res = utils_new.optimize(\n",
        "    params_0, FLAGS.n, FLAGS.f, FLAGS.m, lbfgs_options, bfgs_options, out_dir,\n",
        "    FLAGS.checkpoint_freq)`\n",
        "\n",
        "    Here, `outdir` and `checkpoint_freq` are inputs to `write_checkpoint`which is defined in utils.py or utils_new.py. Every `checkpoint_freq` iterations, it stores:\n",
        "      - the current raw parameter values :\n",
        "     `np.savez(result_path, weights=weights, pos_spectrum=pos_spectrum neg_spectrum=neg_spectrum, alphas=alphas, betas=betas)`\n",
        "      - the current meaningful parameters, reshaping the raw parameters as eigenvectors, eingenvalues...This reshaping is performed by the `collect_results` function in utils_new.py  which outputs a dictonary called results with all this interpretable information\n",
        "      `results.update(collect_results(params))\n",
        "       np.savez(result_path, **results)`\n",
        "\n",
        "      - While the raw parameters are saved as a separated .npz file at each step, the result dictionary is overwritten at each step\n",
        "\n",
        "\n",
        "* final output:\n",
        "   - We use the `write_checkpoint` function to store the optimal parameters and add $n$,$f$, $m$ and the results of the optimisation to the `results dictionary`:\n",
        "  - ```results = defaultdict(list)\n",
        "      results['n'] = FLAGS.n\n",
        "      results['f'] = FLAGS.f\n",
        "      results['m'] = FLAGS.m\n",
        "\n",
        "      final_params, bfgs_res = utils.optimize(....)\n",
        "      results.update(bfgs_res)\n",
        "      utils.write_checkpoint(final_params, 'parameters_last', out_dir, results)\n",
        "    ```\n",
        "\n",
        "##A few test runs:\n",
        "With working directory at cfs_numerics_v2024:\n",
        "\n",
        "- checking run_new.py works:`python ./src/run_new.py --f=2 --n=1 --m=16 --seed=4`\n",
        "- checking run_new_optimistix.py works without boundedness constraint:`python ./src/run_new_optimistix.py --f=2 --n=1 --m=16 --seed=4`\n",
        "- checking run_new_optimistix.py works with boundedness constraint: `python ./src/run_new_optimistix.py --f=2 --n=1 --m=16 --seed=4 --boundedness=2`\n",
        "\n",
        "\n",
        "#Running the code on an HPC server\n",
        "\n",
        "When one connects to a server, one typically has acces to two types of nodes:\n",
        "\n",
        "- A **login node** where you arrive when you connect to the server. It is used to  launch jobs, run small tests, manage files: everything other than heavy computations.\n",
        "- **compute nodes**: The nodes on which to launch the heavy computations. One does not have direct access to them and must submit a job to SLURM, a job scheduler which whill manage resources between all the submitted jobs efficiently.\n",
        "\n",
        "##Overview:\n",
        "This repository contains shell scripts which are run on the login node:\n",
        "\n",
        "- setup_env.sh\n",
        "- run_test_job.sh\n",
        "- run_gabs_test.sh\n",
        "- run_all_experiments.sh\n",
        "\n",
        "The first two enable us to ensure our  working repository has all the required installs and works properly.\n",
        "\n",
        "The last two are called **batch job launchers** and make the link between the login and compute nodes.\n",
        "\n",
        "They call the  python script cluster_submit.py who  creates **batch scripts** and submits them to SLURM.\n",
        "\n",
        "SLURM will read through these batch scripts and execute the task defined in them on the compute nodes.\n",
        "\n",
        "These tasks in our case are the optimisation problems defined by:\n",
        "- run.py\n",
        "- run_new.py\n",
        "- run_new_optimistix.py\n",
        "\n",
        "with hyperparameters $m$, $f$, $n$... defined in configs.py.\n",
        "\n",
        "## Getting started\n",
        "\n",
        "Once connected to the server, navigate to your working directory and in a bash shell run the shell script\n",
        "setup_env.sh to create a conda environement where the requirements defined in requirements.txt are satisfied.\n",
        "\n",
        "##Batch job launchers\n",
        "\n",
        "###Testing\n",
        "You can now run `run_test_job.sh`.\n",
        "\n",
        "This is a script that will test whether you server environment works well and run a test run on the login node (not on the compute nodes which are managed by SLURM).\n",
        "\n",
        "It does not need cluster_submit.py (whose purpose is to  generate bash scripts) and hence run_test_job.sh directly writes a shell script which activates the conda environment and launches run.py with a simple parameter configuration defined directly in the script:\n",
        "\n",
        "`python ./src/run.py --f=2 --n=1 --m=16 --seed=4`\n",
        "\n",
        "###Running experiments\n",
        "\n",
        "If this works well, you can then run any batch job launcher such as run_all_experiments.sh or run_gabs_test.sh\n",
        "\n",
        "These will run cluster_submit.py based off parameter configurations defined in configs.py:\n",
        "\n",
        "They contain the following commands:\n",
        "\n",
        "- In run_gabs_test.sh:\n",
        "\n",
        "`python \"${script_dir}/src/cluster_submit.py\" --experiment_name=n1_testing_0712 --config=gabs_test --n_runs 1 --runpath=/home/x_rojon/cfs_numerics_v2024/src/run.py --result_dir=/home/x_rojon/results/`\n",
        "\n",
        "- In run_all_experiments.sh:\n",
        "\n",
        "`python src/cluster_submit.py --experiment_name=n1_large_f --config=n1_large_f --n_runs 1`\n",
        "\n",
        "This shows that cluster_submit.py requires\n",
        "\n",
        "- an experiment name to store the experiment under an appropriate name\n",
        "-  a configuration such as `gabs_test` or `n1_large_f` which are both defined in config.py\n",
        "- the path to the python script that we want to run `runpath`: here the optimisation procedure so runpath can lead to either run.py, run_new.py or run_new_optimistix.py\n",
        "    - you can see in run_gabs_test.sh that the `runpath` refers to the cloned cfs_numerics_v2024 repository on the user's directory on the server and then points to run.py\n",
        "- an output directory `result_dir` so that the server knows where to store the results\n",
        "\n",
        "**Note that run_all_experiments.sh does not specify a `runpath` or a `result_dir`.  It is a legacy code which should be updated  to run correctly**.\n",
        "\n",
        "##Generating and submitting batch scripts: cluster_submit.py\n",
        "\n",
        "When it is called by the above batch job launchers,\n",
        "cluster_submit.py will generate and submit batch scripts to SLURM.\n",
        "\n",
        "It generates a  SLURM batch script (run_job.cmd) which requests resources  (CPU, GPU, time, memory), activates the conda environment, and runs the optimisation Python script.\n",
        "\n",
        "(You can chose that  optimisation python script among run.py, run_new.py or run_new_optimistix.py by modifying the `runpath` flag when calling cluster_submit)\n",
        "\n",
        "cluster_submit.py generates the script through the function `submit_all_jobs` which defines a sequence of lines and then calls\n",
        "\n",
        "`with open(\"run_job.cmd\", \"w\") as file:\n",
        "      file.write(\"\\n\".join(lines))`\n",
        "\n",
        "to create the script under the appropriate name and put together all the lines in the script.\n",
        "\n",
        "It then submits it to slurm using `os.system(\"sbatch run_job.cmd\")`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
